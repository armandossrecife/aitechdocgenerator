# ğŸ“š AutoDocGen - Gerador AutomÃ¡tico de DocumentaÃ§Ã£o TÃ©cnica

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![Flask](https://img.shields.io/badge/Flask-2.3+-green.svg)](https://flask.palletsprojects.com/)
[![Ollama](https://img.shields.io/badge/Ollama-Qwen3-orange.svg)](https://ollama.ai/)

Uma ferramenta web inteligente que analisa repositÃ³rios pÃºblicos do GitHub e gera automaticamente documentaÃ§Ã£o tÃ©cnica completa usando IA Generativa (LLM) local.

## ğŸ¯ Sobre o Projeto

O **AutoDocGen** Ã© uma plataforma web que automatiza a criaÃ§Ã£o de documentaÃ§Ã£o tÃ©cnica para projetos de software. Utilizando o poder da InteligÃªncia Artificial Generativa atravÃ©s do Ollama com o modelo Qwen3, a ferramenta analisa repositÃ³rios do GitHub e produz documentaÃ§Ã£o estruturada incluindo:

- âœ… **Requisitos Funcionais e NÃ£o-Funcionais**
- âœ… **Arquitetura de Software (C4, MVC, Camadas)**
- âœ… **Diagramas em Mermaid**
- âœ… **Stack TecnolÃ³gica e DependÃªncias**
- âœ… **Resumo Executivo do Projeto**

## ğŸš€ Funcionalidades

- ğŸ” **AutenticaÃ§Ã£o segura** com JWT
- ğŸ“¦ **AnÃ¡lise de repositÃ³rios pÃºblicos** do GitHub
- ğŸ¤– **GeraÃ§Ã£o automÃ¡tica de documentaÃ§Ã£o** com IA
- ğŸ“Š **Dashboard interativo** com histÃ³rico de anÃ¡lises
- ğŸ“„ **ExportaÃ§Ã£o em Markdown e PDF**
- ğŸ¨ **Diagramas arquiteturais** em Mermaid (C4, MVC, MÃ³dulos)
- âš¡ **Processamento assÃ­ncrono** de anÃ¡lises
- ğŸ’¾ **Armazenamento persistente** de resultados

## ğŸ“‹ PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter instalado:

- **Python 3.8+**
- **Ollama** (rodando com o modelo Qwen3)
- **Git** (para clonar o repositÃ³rio)

### Instalando o Ollama

1. Baixe e instale o Ollama em: https://ollama.ai/download

2. Execute no terminal para baixar o modelo Qwen3:
   ```bash
   ollama pull qwen3
   ```

3. Inicie o servidor Ollama:
   ```bash
   ollama serve
   ```

> âš ï¸ **Importante**: O servidor Ollama deve estar rodando em `http://localhost:11434` para que a aplicaÃ§Ã£o funcione corretamente.

## ğŸ› ï¸ InstalaÃ§Ã£o

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/seu-usuario/autodocgen.git
cd autodocgen
```

### 2. Estrutura do Projeto

```
autodocgen/
â”œâ”€â”€ backend/          # API FastAPI
â”œâ”€â”€ frontend/         # Interface Flask
â”œâ”€â”€ storage/          # Arquivos temporÃ¡rios e documentos
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

### 3. InstalaÃ§Ã£o das DependÃªncias

**Backend (FastAPI):**
```bash
cd backend
pip install -r requirements.txt
```

**Frontend (Flask):**
```bash
cd ../frontend
pip install -r requirements.txt
```

## ğŸƒ Executando a AplicaÃ§Ã£o

VocÃª precisarÃ¡ de **dois terminais** abertos simultaneamente.

### Terminal 1: Backend (FastAPI)

```bash
cd backend
uvicorn app.main:app --reload --port 8000
```

âœ… O backend estarÃ¡ rodando em: **http://127.0.0.1:8000**

### Terminal 2: Frontend (Flask)

```bash
cd frontend
python app.py
```

âœ… O frontend estarÃ¡ rodando em: **http://127.0.0.1:5000**

## ğŸ“– Usando o Sistema

### Passo a Passo

1. **Acesse a aplicaÃ§Ã£o**
   - Abra seu navegador e vÃ¡ para: http://127.0.0.1:5000

2. **Crie sua conta**
   - Clique em "Register" no menu
   - Preencha seus dados e crie uma conta

3. **FaÃ§a login**
   - Use suas credenciais para acessar o dashboard

4. **Adicione um repositÃ³rio**
   - No dashboard, clique em "Adicionar RepositÃ³rio"
   - Insira a URL de um repositÃ³rio pÃºblico do GitHub
   - Exemplo: `https://github.com/psf/requests`

5. **Inicie a anÃ¡lise**
   - Clique em "Analyze ğŸš€"
   - Aguarde o processamento (pode levar alguns minutos)

6. **Visualize e baixe a documentaÃ§Ã£o**
   - Acesse o histÃ³rico de anÃ¡lises
   - Visualize a documentaÃ§Ã£o gerada
   - Baixe em formato Markdown ou PDF

## ğŸ¨ Exemplo de DocumentaÃ§Ã£o Gerada

### Estrutura da DocumentaÃ§Ã£o

```markdown
# DocumentaÃ§Ã£o TÃ©cnica - [Nome do Projeto]

## 1. Documento de Requisitos

### 1.1 Requisitos Funcionais
- [Baseado no README e estrutura do projeto]

### 1.2 Requisitos NÃ£o-Funcionais
- Desempenho: [AnÃ¡lise de benchmarks]
- SeguranÃ§a: [PrÃ¡ticas identificadas]
- Portabilidade: [Compatibilidade detectada]

## 2. Documento de Arquitetura

### 2.1 Diagrama C4 (Context)
```mermaid
graph LR
    A[UsuÃ¡rio] --> B[Sistema]
    B --> C[Banco de Dados]
```

### 2.2 Arquitetura MVC/Camadas
[Diagrama gerado automaticamente]

### 2.3 Diagrama de MÃ³dulos
[Diagrama de pacotes]

## 3. Stack TecnolÃ³gica

### 3.1 Linguagens e Frameworks
- Python 3.9
- FastAPI
- SQLAlchemy

### 3.2 Comandos de Build/Run
```bash
pip install -r requirements.txt
uvicorn app.main:app --reload
```

### 3.3 Estrutura do Projeto
```
project/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ services/
â”‚   â””â”€â”€ models/
â””â”€â”€ tests/
```

## 4. Resumo Executivo
[Resumo automÃ¡tico do projeto]
```

## ğŸ› ï¸ Tecnologias Utilizadas

### Backend
- **FastAPI** - Framework web moderno e rÃ¡pido
- **SQLAlchemy** - ORM para banco de dados
- **PyJWT** - AutenticaÃ§Ã£o JWT
- **HTTPX** - Cliente HTTP assÃ­ncrono
- **Ollama Client** - IntegraÃ§Ã£o com LLM

### Frontend
- **Flask** - Framework web leve
- **Bootstrap 5.2** - Design responsivo
- **JavaScript** - Interatividade

### Banco de Dados
- **SQLite** - Banco de dados relacional (MVP)
- **PostgreSQL** - Recomendado para produÃ§Ã£o

### IA Generativa
- **Ollama** - Servidor de LLM local
- **Qwen3** - Modelo de linguagem de cÃ³digo aberto

## ğŸ“ Estrutura de Arquivos

```bash
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ repos.py
â”‚   â”‚   â”œâ”€â”€ analyses.py
â”‚   â”‚   â””â”€â”€ docs.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ github_fetcher.py
â”‚   â”‚   â”œâ”€â”€ repo_indexer.py
â”‚   â”‚   â”œâ”€â”€ readme_parser.py
â”‚   â”‚   â”œâ”€â”€ stack_detector.py
â”‚   â”‚   â”œâ”€â”€ context_builder.py
â”‚   â”‚   â”œâ”€â”€ ollama_client.py
â”‚   â”‚   â”œâ”€â”€ doc_generator.py
â”‚   â”‚   â””â”€â”€ diagram_generator.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ repository.py
â”‚   â”‚   â”œâ”€â”€ analysis_job.py
â”‚   â”‚   â””â”€â”€ document.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ repos/
â”‚   â””â”€â”€ docs/
â””â”€â”€ requirements.txt
```

```bash
frontend/
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ base.html
â”‚   â”œâ”€â”€ auth/
â”‚   â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ analyses/
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”œâ”€â”€ js/
â”‚   â””â”€â”€ img/
â”œâ”€â”€ app.py
â””â”€â”€ requirements.txt
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente

Crie um arquivo `.env` na pasta `backend/`:

```env
# Database
DATABASE_URL=sqlite:///./storage/app.db

# JWT
SECRET_KEY=sua_chave_secreta_aqui
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen3

# GitHub
GITHUB_API_TOKEN=seu_token_aqui (opcional)

# Limits
MAX_REPO_SIZE_MB=100
MAX_FILE_COUNT=500
ANALYSIS_TIMEOUT_SECONDS=300
```

### Docker (Opcional)

Para executar com Docker:

```bash
docker-compose up --build
```

## ğŸ› Troubleshooting

### Ollama nÃ£o estÃ¡ respondendo
```bash
# Verifique se o Ollama estÃ¡ rodando
curl http://localhost:11434/api/version

# Se nÃ£o estiver, inicie o servidor
ollama serve
```

### Erro de dependÃªncias
```bash
# Atualize o pip
pip install --upgrade pip

# Reinstale as dependÃªncias
pip install -r requirements.txt --force-reinstall
```

### Banco de dados corrompido
```bash
# Remova o banco de dados (cuidado: apaga todos os dados)
rm backend/storage/app.db

# O banco serÃ¡ recriado na prÃ³xima inicializaÃ§Ã£o
```

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, siga estes passos:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## ğŸ“ Roadmap

- [ ] Suporte a repositÃ³rios privados (OAuth GitHub)
- [ ] AnÃ¡lise incremental (detectar mudanÃ§as)
- [ ] ComparaÃ§Ã£o de versÃµes
- [ ] IntegraÃ§Ã£o com CI/CD
- [ ] Suporte a mÃºltiplos modelos LLM
- [ ] Interface de administraÃ§Ã£o
- [ ] Sistema de notificaÃ§Ãµes
- [ ] API pÃºblica para integraÃ§Ãµes

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ‘¥ Autores

Desenvolvido por [Armando Soares Sousa]

## ğŸ™ Agradecimentos

- Ollama Team pelo excelente trabalho com LLMs locais
- FastAPI e Flask communities
- Todos os contribuidores e usuÃ¡rios

## ğŸ“ Suporte

Para suporte, por favor abra uma issue no repositÃ³rio ou entre em contato em [armando@ufpi.edu.br].
